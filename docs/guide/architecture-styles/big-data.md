---
title: Architekturstil für Big Data
description: Dieser Artikel beschreibt die Vorteile, Herausforderungen und bewährten Methoden für Big Data-Architekturen in Azure.
author: MikeWasson
ms.openlocfilehash: 4e8b58d5fa0f6a441d70e05ec7d6a0e668712563
ms.sourcegitcommit: b0482d49aab0526be386837702e7724c61232c60
ms.translationtype: HT
ms.contentlocale: de-DE
ms.lasthandoff: 11/14/2017
---
# <a name="big-data-architecture-style"></a><span data-ttu-id="88aff-103">Architekturstil für Big Data</span><span class="sxs-lookup"><span data-stu-id="88aff-103">Big data architecture style</span></span>

<span data-ttu-id="88aff-104">Eine Big Data-Architektur ist für die Erfassung, Verarbeitung und Analyse von Daten konzipiert, die für herkömmliche Datenbanksysteme zu groß oder zu komplex sind.</span><span class="sxs-lookup"><span data-stu-id="88aff-104">A big data architecture is designed to handle the ingestion, processing, and analysis of data that is too large or complex for traditional database systems.</span></span>

![](./images/big-data-logical.svg)

 <span data-ttu-id="88aff-105">Big Data-Lösungen umfassen üblicherweise mindestens einen der folgenden Workloadtypen:</span><span class="sxs-lookup"><span data-stu-id="88aff-105">Big data solutions typically involve one or more of the following types of workload:</span></span>

- <span data-ttu-id="88aff-106">Batchverarbeitung von ruhenden Big Data-Quellen</span><span class="sxs-lookup"><span data-stu-id="88aff-106">Batch processing of big data sources at rest.</span></span>
- <span data-ttu-id="88aff-107">Echtzeitverarbeitung von Big Data während der Übertragung</span><span class="sxs-lookup"><span data-stu-id="88aff-107">Real-time processing of big data in motion.</span></span>
- <span data-ttu-id="88aff-108">Interaktive Erkundung von Big Data.</span><span class="sxs-lookup"><span data-stu-id="88aff-108">Interactive exploration of big data.</span></span>
- <span data-ttu-id="88aff-109">Predictive Analytics und Machine Learning</span><span class="sxs-lookup"><span data-stu-id="88aff-109">Predictive analytics and machine learning.</span></span>

<span data-ttu-id="88aff-110">Die meisten Big Data-Architekturen enthalten einige oder alle der folgenden Komponenten:</span><span class="sxs-lookup"><span data-stu-id="88aff-110">Most big data architectures include some or all of the following components:</span></span>

- <span data-ttu-id="88aff-111">**Datenquellen**. Alle Big Data-Lösungen beginnen mit mindestens einer Datenquelle.</span><span class="sxs-lookup"><span data-stu-id="88aff-111">**Data sources**: All big data solutions start with one or more data sources.</span></span> <span data-ttu-id="88aff-112">Beispiele:</span><span class="sxs-lookup"><span data-stu-id="88aff-112">Examples include:</span></span>

    - <span data-ttu-id="88aff-113">Anwendungsdatenspeicher wie z.B. relationale Datenbanken</span><span class="sxs-lookup"><span data-stu-id="88aff-113">Application data stores, such as relational databases.</span></span>
    - <span data-ttu-id="88aff-114">Von Anwendungen erzeugte statische Dateien, z.B. Webserver-Protokolldateien</span><span class="sxs-lookup"><span data-stu-id="88aff-114">Static files produced by applications, such as web server log files.</span></span>
    - <span data-ttu-id="88aff-115">Echtzeitdatenquellen wie z.B. IoT-Geräte</span><span class="sxs-lookup"><span data-stu-id="88aff-115">Real-time data sources, such as IoT devices.</span></span>

- <span data-ttu-id="88aff-116">**Datenspeicher**. Daten für die Batchverarbeitung werden in der Regel in einem verteilten Dateispeicher gespeichert, der große Mengen umfangreicher Dateien in verschiedenen Formaten aufnehmen kann.</span><span class="sxs-lookup"><span data-stu-id="88aff-116">**Data storage**: Data for batch processing operations is typically stored in a distributed file store that can hold high volumes of large files in various formats.</span></span> <span data-ttu-id="88aff-117">Diese Art Speicher wird häufig als *Data Lake* bezeichnet.</span><span class="sxs-lookup"><span data-stu-id="88aff-117">This kind of store is often called a *data lake*.</span></span> <span data-ttu-id="88aff-118">Ein solcher Speicher lässt sich beispielsweise über Azure Data Lake Store oder Blobcontainer in Azure Storage implementieren.</span><span class="sxs-lookup"><span data-stu-id="88aff-118">Options for implementing this storage include Azure Data Lake Store or blob containers in Azure Storage.</span></span> 

- <span data-ttu-id="88aff-119">**Batchverarbeitung**. Da die Datasets so umfangreich sind, muss eine Big Data-Lösung Datendateien mithilfe von Batchaufträgen mit langer Ausführungszeit verarbeiten, um die Daten zu filtern, zu aggregieren und auch anderweitig auf die Analyse vorzubereiten.</span><span class="sxs-lookup"><span data-stu-id="88aff-119">**Batch processing**: Because the data sets are so large, often a big data solution must process data files using long-running batch jobs to filter, aggregate, and otherwise prepare the data for analysis.</span></span> <span data-ttu-id="88aff-120">Diese Aufträge beinhalten in der Regel das Lesen von Quelldateien, ihre Verarbeitung und das Schreiben der Ausgabe in neue Dateien.</span><span class="sxs-lookup"><span data-stu-id="88aff-120">Usually these jobs involve reading source files, processing them, and writing the output to new files.</span></span> <span data-ttu-id="88aff-121">Zu den Optionen gehört z.B. Folgendes: die Ausführung von U-SQL-Aufträgen in Azure Data Lake Analytics, die Verwendung von Hive-, Pig- oder benutzerdefinierten MapReduce-Aufträgen in einem HDInsight Hadoop-Cluster oder die Verwendung von Java-, Scala- oder Python-Programmen in einem HDInsight Spark-Cluster.</span><span class="sxs-lookup"><span data-stu-id="88aff-121">Options include running U-SQL jobs in Azure Data Lake Analytics, using Hive, Pig, or custom Map/Reduce jobs in an HDInsight Hadoop cluster, or using Java, Scala, or Python programs in an HDInsight Spark cluster.</span></span>

- <span data-ttu-id="88aff-122">**Echtzeiterfassung von Nachrichten**. Wenn die Lösung Echtzeitquellen umfasst, muss die Architektur eine Möglichkeit bieten, Echtzeitnachrichten für die Verarbeitung des Datenstroms zu erfassen und zu speichern.</span><span class="sxs-lookup"><span data-stu-id="88aff-122">**Real-time message ingestion**: If the solution includes real-time sources, the architecture must include a way to capture and store real-time messages for stream processing.</span></span> <span data-ttu-id="88aff-123">Hierbei kann es sich um einen einfachen Datenspeicher handeln, in dem eingehende Nachrichten zur Verarbeitung in einem Ordner abgelegt werden.</span><span class="sxs-lookup"><span data-stu-id="88aff-123">This might be a simple data store, where incoming messages are dropped into a folder for processing.</span></span> <span data-ttu-id="88aff-124">Viele Lösungen benötigen jedoch einen Speicher für die Erfassung von Nachrichten, der als Puffer für Nachrichten fungiert. Der Speicher muss zudem die Verarbeitung der horizontalen Skalierung, eine zuverlässige Übermittlung sowie weitere Semantik für das Nachrichtenqueuing unterstützen.</span><span class="sxs-lookup"><span data-stu-id="88aff-124">However, many solutions need a message ingestion store to act as a buffer for messages, and to support scale-out processing, reliable delivery, and other message queuing semantics.</span></span> <span data-ttu-id="88aff-125">Zu den Optionen gehören Azure Event Hubs, Azure IoT Hubs und Kafka.</span><span class="sxs-lookup"><span data-stu-id="88aff-125">Options include Azure Event Hubs, Azure IoT Hubs, and Kafka.</span></span>

- <span data-ttu-id="88aff-126">**Datenstromverarbeitung**. Nach dem Erfassen von Echtzeitnachrichten muss die Lösung diese verarbeiten, indem die Daten gefiltert, aggregiert und auch anderweitig auf die Analyse vorbereitet werden.</span><span class="sxs-lookup"><span data-stu-id="88aff-126">**Stream processing**: After capturing real-time messages, the solution must process them by filtering, aggregating, and otherwise preparing the data for analysis.</span></span> <span data-ttu-id="88aff-127">Die verarbeiteten Daten aus dem Datenstrom werden dann in eine Ausgabesenke geschrieben.</span><span class="sxs-lookup"><span data-stu-id="88aff-127">The processed stream data is then written to an output sink.</span></span> <span data-ttu-id="88aff-128">Azure Stream Analytics stellt einen verwalteten Dienst für die Datenstromverarbeitung bereit, basierend auf kontinuierlich ausgeführten SQ-Abfragen, die in ungebundenen Datenströmen arbeiten.</span><span class="sxs-lookup"><span data-stu-id="88aff-128">Azure Stream Analytics provides a managed stream processing service based on perpetually running SQL queries that operate on unbounded streams.</span></span> <span data-ttu-id="88aff-129">Sie können auch Open Source-Apache-Streamingtechnologien wie Storm und Spark Streaming in einem HDInsight-Cluster verwenden.</span><span class="sxs-lookup"><span data-stu-id="88aff-129">You can also use open source Apache streaming technologies like Storm and Spark Streaming in an HDInsight cluster.</span></span>

- <span data-ttu-id="88aff-130">**Analysedatenspeicher**: Viele Big Data-Lösungen bereiten Daten für die Analyse vor und stellen die verarbeiteten Daten dann in einem strukturierten Format bereit, das mithilfe von Analysetools abgefragt werden kann.</span><span class="sxs-lookup"><span data-stu-id="88aff-130">**Analytical data store**: Many big data solutions prepare data for analysis and then serve the processed data in a structured format that can be queried using analytical tools.</span></span> <span data-ttu-id="88aff-131">Der Analysedatenspeicher, in dem diese Abfragen ausgeführt werden, kann ein relationales Data Warehouse im Kimball-Stil sein, wie es in den meisten herkömmlichen BI-Lösungen (Business Intelligence) zu finden ist.</span><span class="sxs-lookup"><span data-stu-id="88aff-131">The analytical data store used to serve these queries can be a Kimball-style relational data warehouse, as seen in most traditional business intelligence (BI) solutions.</span></span> <span data-ttu-id="88aff-132">Alternativ dazu können die Daten auch über eine NoSQL-Technologie mit niedriger Latenz bereitgestellt werden, wie z.B. HBase. Eine weitere Möglichkeit ist eine interaktive Hive-Datenbank, die eine Metadatenabstraktion der Datendateien in einem verteilten Datenspeicher bereitstellt.</span><span class="sxs-lookup"><span data-stu-id="88aff-132">Alternatively, the data could be presented through a low-latency NoSQL technology such as HBase, or an interactive Hive database that provides a metadata abstraction over data files in the distributed data store.</span></span> <span data-ttu-id="88aff-133">Azure SQL Data Warehouse bietet einen verwalteten Dienst für umfangreiches cloudbasiertes Data Warehousing.</span><span class="sxs-lookup"><span data-stu-id="88aff-133">Azure SQL Data Warehouse provides a managed service for large-scale, cloud-based data warehousing.</span></span> <span data-ttu-id="88aff-134">HDInsight unterstützt Interactive Hive, HBase und Spark SQL – diese Module können auch zum Bereitstellen von Daten für die Analyse verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="88aff-134">HDInsight supports Interactive Hive, HBase, and Spark SQL, which can also be used to serve data for analysis.</span></span>

- <span data-ttu-id="88aff-135">**Analysen und Berichte**. Ziel der meisten Big Data-Lösungen ist es, über Analysen und Berichte Einblicke in die Daten zu bieten.</span><span class="sxs-lookup"><span data-stu-id="88aff-135">**Analysis and reporting**: The goal of most big data solutions is to provide insights into the data through analysis and reporting.</span></span> <span data-ttu-id="88aff-136">Um Benutzer die Datenanalyse zu ermöglichen, kann die Architektur eine Datenmodellierungsschicht umfassen, wie z.B. einen multidimensionalen OLAP-Cube oder ein Tabellendatenmodell in Azure Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="88aff-136">To empower users to analyze the data, the architecture may include a data modeling layer, such as a multidimensional OLAP cube or tabular data model in Azure Analysis Services.</span></span> <span data-ttu-id="88aff-137">Sie kann auch Self-Service-BI unterstützen – hierbei kommen die Modellierungs- und Visualisierungstechnologien von Microsoft Power BI oder Microsoft Excel zum Einsatz.</span><span class="sxs-lookup"><span data-stu-id="88aff-137">It might also support self-service BI, using the modeling and visualization technologies in Microsoft Power BI or Microsoft Excel.</span></span> <span data-ttu-id="88aff-138">Analysen und Berichterstellung können auch in Form einer interaktiven Datenerkundung durch Data Scientists oder Data Analysts erfolgen.</span><span class="sxs-lookup"><span data-stu-id="88aff-138">Analysis and reporting can also take the form of interactive data exploration by data scientists or data analysts.</span></span> <span data-ttu-id="88aff-139">Für diese Szenarios unterstützen viele Azure-Dienste Analysenotebooks, z.B. Jupyter, sodass diese Benutzer ihre vorhandenen Kenntnisse von Python oder R nutzen können. Zum Erkunden sehr umfangreicher Daten können Sie Microsoft R Server als eigenständige Lösung oder zusammen mit Spark verwenden.</span><span class="sxs-lookup"><span data-stu-id="88aff-139">For these scenarios, many Azure services support analytical notebooks, such as Jupyter, enabling these users to leverage their existing skills with Python or R. For large-scale data exploration, you can use Microsoft R Server, either standalone or with Spark.</span></span>

- <span data-ttu-id="88aff-140">**Orchestrierung**. Die meisten Big Data-Lösungen bestehen aus wiederholten Datenverarbeitungsvorgängen, die in Workflows gekapselt sind. Diese Vorgänge transformieren Quelldaten, verschieben Daten zwischen mehreren Quellen und Senken, laden die verarbeiteten Daten in einen Analysedatenspeicher oder übermitteln die Ergebnisse direkt in einen Bericht oder auf ein Dashboard.</span><span class="sxs-lookup"><span data-stu-id="88aff-140">**Orchestration**: Most big data solutions consist of repeated data processing operations, encapsulated in workflows, that transform source data, move data between multiple sources and sinks, load the processed data into an analytical data store, or push the results straight to a report or dashboard.</span></span> <span data-ttu-id="88aff-141">Um diese Workflows zu automatisieren, können Sie eine Orchestrierungstechnologie wie such Azure Data Factory oder Apache Oozie und Sqoop verwenden.</span><span class="sxs-lookup"><span data-stu-id="88aff-141">To automate these workflows, you can use an orchestration technology such Azure Data Factory or Apache Oozie and Sqoop.</span></span>

<span data-ttu-id="88aff-142">Azure bietet eine Vielzahl von Diensten, die in einer Big Data-Architektur verwendet werden können.</span><span class="sxs-lookup"><span data-stu-id="88aff-142">Azure includes many services that can be used in a big data architecture.</span></span> <span data-ttu-id="88aff-143">Sie lassen sich in zwei Kategorien unterteilen:</span><span class="sxs-lookup"><span data-stu-id="88aff-143">They fall roughly into two categories:</span></span>

- <span data-ttu-id="88aff-144">Verwaltete Dienste, einschließlich Azure Data Lake Store, Azure Data Lake Analytics, Azure Data Warehouse, Azure Stream Analytics, Azure Event Hub, Azure IoT Hub und Azure Data Factory.</span><span class="sxs-lookup"><span data-stu-id="88aff-144">Managed services, including Azure Data Lake Store, Azure Data Lake Analytics, Azure Data Warehouse, Azure Stream Analytics, Azure Event Hub, Azure IoT Hub, and Azure Data Factory.</span></span>
- <span data-ttu-id="88aff-145">Auf der Apache Hadoop-Plattform basierende Open Source-Technologien, einschließlich HDFS, HBase, Hive, Pig, Spark, Storm, Oozie, Sqoop und Kafka.</span><span class="sxs-lookup"><span data-stu-id="88aff-145">Open source technologies based on the Apache Hadoop platform, including HDFS, HBase, Hive, Pig, Spark, Storm, Oozie, Sqoop, and Kafka.</span></span> <span data-ttu-id="88aff-146">Diese Technologien sind in Azure im Azure HDInsight-Dienst verfügbar.</span><span class="sxs-lookup"><span data-stu-id="88aff-146">These technologies are available on Azure in the Azure HDInsight service.</span></span>

<span data-ttu-id="88aff-147">Diese Optionen schließen sich nicht gegenseitig aus, und viele Lösungen kombinieren Open Source-Technologien mit Azure-Diensten.</span><span class="sxs-lookup"><span data-stu-id="88aff-147">These options are not mutually exclusive, and many solutions combine open source technologies with Azure services.</span></span>

## <a name="when-to-use-this-architecture"></a><span data-ttu-id="88aff-148">Einsatzmöglichkeiten für diese Architektur</span><span class="sxs-lookup"><span data-stu-id="88aff-148">When to use this architecture</span></span>

<span data-ttu-id="88aff-149">Ziehen Sie diese Art von Architektur in folgenden Fällen in Betracht:</span><span class="sxs-lookup"><span data-stu-id="88aff-149">Consider this architecture style when you need to:</span></span>

- <span data-ttu-id="88aff-150">Sie möchten Daten in Mengen speichern und verarbeiten, die für eine herkömmliche Datenbank zu groß sind.</span><span class="sxs-lookup"><span data-stu-id="88aff-150">Store and process data in volumes too large for a traditional database.</span></span>
- <span data-ttu-id="88aff-151">Sie möchten unstrukturierte Daten zum Zweck der Analyse und Berichterstellung transformieren.</span><span class="sxs-lookup"><span data-stu-id="88aff-151">Transform unstructured data for analysis and reporting.</span></span>
- <span data-ttu-id="88aff-152">Sie möchten ungebundene Datenströme in Echtzeit oder mit geringer Latenz erfassen, verarbeiten und analysieren.</span><span class="sxs-lookup"><span data-stu-id="88aff-152">Capture, process, and analyze unbounded streams of data in real time, or with low latency.</span></span>
- <span data-ttu-id="88aff-153">Sie möchten Azure Machine Learning oder Microsoft Cognitive Services verwenden.</span><span class="sxs-lookup"><span data-stu-id="88aff-153">Use Azure Machine Learning or Microsoft Cognitive Services.</span></span>

## <a name="benefits"></a><span data-ttu-id="88aff-154">Vorteile</span><span class="sxs-lookup"><span data-stu-id="88aff-154">Benefits</span></span>

- <span data-ttu-id="88aff-155">**Auswahlmöglichkeiten bei der Technologie**.</span><span class="sxs-lookup"><span data-stu-id="88aff-155">**Technology choices**.</span></span> <span data-ttu-id="88aff-156">Sie können verwaltete Azure-Dienste und Apache-Technologien gemeinsam in HDInsight-Clustern einsetzen, um vorhandene Kenntnisse und Technologieinvestitionen optimal auszuschöpfen.</span><span class="sxs-lookup"><span data-stu-id="88aff-156">You can mix and match Azure managed services and Apache technologies in HDInsight clusters, to capitalize on existing skills or technology investments.</span></span>
- <span data-ttu-id="88aff-157">**Bessere Leistung durch Parallelität**.</span><span class="sxs-lookup"><span data-stu-id="88aff-157">**Performance through parallelism**.</span></span> <span data-ttu-id="88aff-158">Big Data-Lösungen profitieren von Parallelität, die hochleistungsfähige Lösungen ermöglicht, die sich auf sehr große Datenmengen skalieren lassen.</span><span class="sxs-lookup"><span data-stu-id="88aff-158">Big data solutions take advantage of parallelism, enabling high-performance solutions that scale to large volumes of data.</span></span>
- <span data-ttu-id="88aff-159">**Elastische Skalierung**.</span><span class="sxs-lookup"><span data-stu-id="88aff-159">**Elastic scale**.</span></span> <span data-ttu-id="88aff-160">Alle Komponenten der Big Data-Architektur unterstützen die horizontale Skalierung, sodass Sie Ihre Lösung auf kleine oder große Workloads ausrichten können und nur für die Ressourcen bezahlen, die Sie tatsächlich nutzen.</span><span class="sxs-lookup"><span data-stu-id="88aff-160">All of the components in the big data architecture support scale-out provisioning, so that you can adjust your solution to small or large workloads, and pay only for the resources that you use.</span></span>
- <span data-ttu-id="88aff-161">**Interoperabilität mit vorhandenen Lösungen**.</span><span class="sxs-lookup"><span data-stu-id="88aff-161">**Interoperability with existing solutions**.</span></span> <span data-ttu-id="88aff-162">Die Komponenten der Big Data-Architektur werden auch für die IoT-Verarbeitung und BI-Unternehmenslösungen verwendet, sodass Sie eine integrierte Lösung für alle Datenworkloads erstellen können.</span><span class="sxs-lookup"><span data-stu-id="88aff-162">The components of the big data architecture are also used for IoT processing and enterprise BI solutions, enabling you to create an integrated solution across data workloads.</span></span>

## <a name="challenges"></a><span data-ttu-id="88aff-163">Herausforderungen</span><span class="sxs-lookup"><span data-stu-id="88aff-163">Challenges</span></span>

- <span data-ttu-id="88aff-164">**Komplexität**.</span><span class="sxs-lookup"><span data-stu-id="88aff-164">**Complexity**.</span></span> <span data-ttu-id="88aff-165">Big Data-Lösungen können sehr komplex sein und eine Vielzahl von Komponenten umfassen, um die aus unterschiedlichsten Datenquellen erfassten Daten zu verarbeiten.</span><span class="sxs-lookup"><span data-stu-id="88aff-165">Big data solutions can be extremely complex, with numerous components to handle data ingestion from multiple data sources.</span></span> <span data-ttu-id="88aff-166">Erstellung, Testing und Problembehebung können bei Big Data-Prozessen eine große Herausforderung darstellen.</span><span class="sxs-lookup"><span data-stu-id="88aff-166">It can be challenging to build, test, and troubleshoot big data processes.</span></span> <span data-ttu-id="88aff-167">Darüber hinaus gibt es wahrscheinlich sehr viele Konfigurationseinstellungen über mehrere Systeme hinweg, die zum Optimieren der Leistung verwendet werden müssen.</span><span class="sxs-lookup"><span data-stu-id="88aff-167">Moreover, there may be a large number of configuration settings across multiple systems that must be used in order to optimize performance.</span></span>
- <span data-ttu-id="88aff-168">**Kompetenz**.</span><span class="sxs-lookup"><span data-stu-id="88aff-168">**Skillset**.</span></span> <span data-ttu-id="88aff-169">Viele Big Data-Technologien sind in hohem Maß spezialisiert und arbeiten mit Frameworks und Sprachen, die in allgemeineren Anwendungsarchitekturen in der Regel nicht verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="88aff-169">Many big data technologies are highly specialized, and use frameworks and languages that are not typical of more general application architectures.</span></span> <span data-ttu-id="88aff-170">Andererseits entstehen durch Big Data-Technologien neue APIs, die auf etablierteren Sprachen basieren.</span><span class="sxs-lookup"><span data-stu-id="88aff-170">On the other hand, big data technologies are evolving new APIs that build on more established languages.</span></span> <span data-ttu-id="88aff-171">Die Sprache U-SQL in Azure Data Lake Analytics beispielsweise basiert auf einer Kombination aus Transact-SQL und C#.</span><span class="sxs-lookup"><span data-stu-id="88aff-171">For example, the U-SQL language in Azure Data Lake Analytics is based on a combination of Transact-SQL and C#.</span></span> <span data-ttu-id="88aff-172">Ebenso sind SQL-basierte APIs für Hive, HBase und Spark verfügbar.</span><span class="sxs-lookup"><span data-stu-id="88aff-172">Similarly, SQL-based APIs are available for Hive, HBase, and Spark.</span></span>
- <span data-ttu-id="88aff-173">**Reife der Technologie**.</span><span class="sxs-lookup"><span data-stu-id="88aff-173">**Technology maturity**.</span></span> <span data-ttu-id="88aff-174">Viele der für Big Data verwendeten Technologien sind noch nicht vollständig ausgereift.</span><span class="sxs-lookup"><span data-stu-id="88aff-174">Many of the technologies used in big data are evolving.</span></span> <span data-ttu-id="88aff-175">Während die Kerntechnologien für Hadoop – wie etwa Hive und Pig – bereits stabil sind, führen aufkommende Technologien wie Spark mit jedem neuen Release umfassende Änderungen und Erweiterungen ein.</span><span class="sxs-lookup"><span data-stu-id="88aff-175">While core Hadoop technologies such as Hive and Pig have stabilized, emerging technologies such as Spark introduce extensive changes and enhancements with each new release.</span></span> <span data-ttu-id="88aff-176">Verwaltete Dienste wie Azure Data Lake Analytics und Azure Data Factory sind im Vergleich zu anderen Azure-Diensten verhältnismäßig jung und werden sich wahrscheinlich im Lauf der Zeit weiterentwickeln.</span><span class="sxs-lookup"><span data-stu-id="88aff-176">Managed services such as Azure Data Lake Analytics and Azure Data Factory are relatively young, compared with other Azure services, and will likely evolve over time.</span></span>
- <span data-ttu-id="88aff-177">**Sicherheit**.</span><span class="sxs-lookup"><span data-stu-id="88aff-177">**Security**.</span></span> <span data-ttu-id="88aff-178">Big Data-Lösungen speichern in der Regel alle statischen Daten in einem zentralen Data Lake.</span><span class="sxs-lookup"><span data-stu-id="88aff-178">Big data solutions usually rely on storing all static data in a centralized data lake.</span></span> <span data-ttu-id="88aff-179">Die Sicherung des Zugriffs auf diese Daten kann eine Herausforderung darstellen, insbesondere dann, wenn die Daten von mehreren Anwendungen und Plattformen erfasst und genutzt werden müssen.</span><span class="sxs-lookup"><span data-stu-id="88aff-179">Securing access to this data can be challenging, especially when the data must be ingested and consumed by multiple applications and platforms.</span></span>

## <a name="best-practices"></a><span data-ttu-id="88aff-180">Bewährte Methoden</span><span class="sxs-lookup"><span data-stu-id="88aff-180">Best practices</span></span>

- <span data-ttu-id="88aff-181">**Parallelität nutzen**.</span><span class="sxs-lookup"><span data-stu-id="88aff-181">**Leverage parallelism**.</span></span> <span data-ttu-id="88aff-182">Die meisten Technologien zur Verarbeitung von Big Data verteilen die Workload auf mehrere Verarbeitungseinheiten.</span><span class="sxs-lookup"><span data-stu-id="88aff-182">Most big data processing technologies distribute the workload across multiple processing units.</span></span> <span data-ttu-id="88aff-183">Dazu müssen die statischen Datendateien in einem teilbaren Format erstellt und gespeichert werden.</span><span class="sxs-lookup"><span data-stu-id="88aff-183">This requires that static data files are created and stored in a splittable format.</span></span> <span data-ttu-id="88aff-184">Verteilte Dateisysteme wie HDFS können die Lese- und Schreibleistung optimieren, und die tatsächliche Verarbeitung wird von mehreren Clusterknoten parallel ausgeführt, wodurch die Auftragsdauer insgesamt reduziert wird.</span><span class="sxs-lookup"><span data-stu-id="88aff-184">Distributed file systems such as HDFS can optimize read and write performance, and the actual processing is performed by multiple cluster nodes in parallel, which reduces overall job times.</span></span>

- <span data-ttu-id="88aff-185">**Daten partitionieren**.</span><span class="sxs-lookup"><span data-stu-id="88aff-185">**Partition data**.</span></span> <span data-ttu-id="88aff-186">Die Batchverarbeitung folgt üblicherweise einem wiederholten Zeitplan – z.B. wöchentlich oder monatlich.</span><span class="sxs-lookup"><span data-stu-id="88aff-186">Batch processing usually happens on a recurring schedule &mdash; for example, weekly or monthly.</span></span> <span data-ttu-id="88aff-187">Partitionieren Sie die Datendateien und Datenstrukturen, wie beispielsweise Tabellen, basierend auf Zeiträumen, die dem Verarbeitungszeitplan entsprechen.</span><span class="sxs-lookup"><span data-stu-id="88aff-187">Partition data files, and data structures such as tables, based on temporal periods that match the processing schedule.</span></span> <span data-ttu-id="88aff-188">So können Sie die Datenerfassung, Auftragsplanung und Problembehebung vereinfachen.</span><span class="sxs-lookup"><span data-stu-id="88aff-188">That simplifies data ingestion and job scheduling, and makes it easier to troubleshoot failures.</span></span> <span data-ttu-id="88aff-189">Durch die Partitionierung von Tabellen, die in Hive-, U-SQL- oder SQL-Abfragen verwendet werden, lässt sich die Abfrageleistung erheblich verbessern.</span><span class="sxs-lookup"><span data-stu-id="88aff-189">Also, partitioning tables that are used in Hive, U-SQL, or SQL queries can significantly improve query performance.</span></span>

- <span data-ttu-id="88aff-190">**Schema-on-Read-Semantik anwenden**.</span><span class="sxs-lookup"><span data-stu-id="88aff-190">**Apply schema-on-read semantics**.</span></span> <span data-ttu-id="88aff-191">Mit einem Data Lake können Sie die Speicherung von Dateien in verschiedenen Formaten kombinieren – unabhängig davon, ob die Dateien strukturiert, semistrukturiert oder unstrukturiert vorliegen.</span><span class="sxs-lookup"><span data-stu-id="88aff-191">Using a data lake lets you to combine storage for files in multiple formats, whether structured, semi-structured, or unstructured.</span></span> <span data-ttu-id="88aff-192">Verwenden Sie die *Schema-on-Read*-Semantik, die bei der Verarbeitung der Daten – nicht beim Speichern der Daten – ein Schema auf die Daten projiziert.</span><span class="sxs-lookup"><span data-stu-id="88aff-192">Use *schema-on-read* semantics, which project a schema onto the data when the data is processing, not when the data is stored.</span></span> <span data-ttu-id="88aff-193">So erreichen Sie mehr Flexibilität für die Lösung und verhindern Engpässe während der Datenerfassung, die durch die Daten- und Typüberprüfung entstehen.</span><span class="sxs-lookup"><span data-stu-id="88aff-193">This builds flexibility into the solution, and prevents bottlenecks during data ingestion caused by data validation and type checking.</span></span>

- <span data-ttu-id="88aff-194">**Daten an Ort und Stelle verarbeiten**.</span><span class="sxs-lookup"><span data-stu-id="88aff-194">**Process data in-place**.</span></span> <span data-ttu-id="88aff-195">Herkömmliche BI-Lösungen verwenden oft einen ETL-Prozess (Extrahieren, Transformieren und Laden), um Daten in ein Data Warehouse zu verschieben.</span><span class="sxs-lookup"><span data-stu-id="88aff-195">Traditional BI solutions often use an extract, transform, and load (ETL) process to move data into a data warehouse.</span></span> <span data-ttu-id="88aff-196">Big Data-Lösungen verarbeiten größere Datenmengen und eine größere Vielfalt an Formaten und verwenden im Allgemeinen ETL-Varianten, z.B. Transformieren, Extrahieren und Laden (TEL).</span><span class="sxs-lookup"><span data-stu-id="88aff-196">With larger volumes data, and a greater variety of formats, big data solutions generally use variations of ETL, such as transform, extract, and load (TEL).</span></span> <span data-ttu-id="88aff-197">Bei diesem Ansatz werden die Daten innerhalb des verteilten Datenspeichers verarbeitet und dabei in die erforderliche Struktur transformiert, bevor die transformierten Daten in einen Analysedatenspeicher verschoben werden.</span><span class="sxs-lookup"><span data-stu-id="88aff-197">With this approach, the data is processed within the distributed data store, transforming it to the required structure, before moving the transformed data into an analytical data store.</span></span>

- <span data-ttu-id="88aff-198">**Die richtige Balance zwischen Nutzung und Kosten für den Zeitaufwand**.</span><span class="sxs-lookup"><span data-stu-id="88aff-198">**Balance utilization and time costs**.</span></span> <span data-ttu-id="88aff-199">Bei Batchverarbeitungsaufträgen müssen zwei Faktoren berücksichtigt werden: die Kosten pro Einheit für die Computeknoten und die Kosten pro Minute für die Verwendung dieser Knoten, um den Auftrag abzuschließen.</span><span class="sxs-lookup"><span data-stu-id="88aff-199">For batch processing jobs, it's important to consider two factors: The per-unit cost of the compute nodes, and the per-minute cost of using those nodes to complete the job.</span></span> <span data-ttu-id="88aff-200">Ein Beispiel: Die Ausführung eines Batchauftrags mit vier Clusterknoten dauert acht Stunden.</span><span class="sxs-lookup"><span data-stu-id="88aff-200">For example, a batch job may take eight hours with four cluster nodes.</span></span> <span data-ttu-id="88aff-201">Nun kann es sein, dass der Auftrag nur während der ersten beiden Stunden alle vier Knoten nutzt und danach nur noch zwei Knoten benötigt.</span><span class="sxs-lookup"><span data-stu-id="88aff-201">However, it might turn out that the job uses all four nodes only during the first two hours, and after that, only two nodes are required.</span></span> <span data-ttu-id="88aff-202">In diesem Fall würde die Ausführung des gesamten Auftrags auf nur zwei Knoten die Gesamtauftragsdauer zwar verlängern, aber nicht verdoppeln, sodass die Gesamtkosten niedriger wären.</span><span class="sxs-lookup"><span data-stu-id="88aff-202">In that case, running the entire job on two nodes would increase the total job time, but would not double it, so the total cost would be less.</span></span> <span data-ttu-id="88aff-203">In einigen Geschäftsszenarien ist eine längere Verarbeitungszeit möglicherweise den höheren Kosten für unzureichend genutzte Clusterressourcen vorzuziehen.</span><span class="sxs-lookup"><span data-stu-id="88aff-203">In some business scenarios, a longer processing time may be preferable to the higher cost of using under-utilized cluster resources.</span></span>

- <span data-ttu-id="88aff-204">**Clusterressourcen trennen**.</span><span class="sxs-lookup"><span data-stu-id="88aff-204">**Separate cluster resources**.</span></span> <span data-ttu-id="88aff-205">Bei HDInsight-Clustern erzielen Sie in der Regel eine bessere Leistung, wenn Sie für jeden Workloadtyp separate Clusterressourcen bereitstellen.</span><span class="sxs-lookup"><span data-stu-id="88aff-205">When deploying HDInsight clusters, you will normally achieve better performance by provisioning separate cluster resources for each type of workload.</span></span> <span data-ttu-id="88aff-206">Ein Beispiel: Spark-Cluster beinhalten zwar Hive, aber wenn Sie eine umfangreiche Verarbeitung sowohl mit Hive als auch mit Spark ausführen müssen, sollten Sie in Betracht ziehen, separate, dedizierte Spark- und Hadoop-Cluster bereitzustellen.</span><span class="sxs-lookup"><span data-stu-id="88aff-206">For example, although Spark clusters include Hive, if you need to perform extensive processing with both Hive and Spark, you should consider deploying separate dedicated Spark and Hadoop clusters.</span></span> <span data-ttu-id="88aff-207">Gleiches gilt, wenn Sie HBase und Storm für die Datenstromverarbeitung mit niedriger Latenz und Hive für die Batchverarbeitung verwenden: Erwägen Sie separate Cluster für Storm, HBase und Hadoop.</span><span class="sxs-lookup"><span data-stu-id="88aff-207">Similarly, if you are using HBase and Storm for low latency stream processing and Hive for batch processing, consider separate clusters for Storm, HBase, and Hadoop.</span></span>

- <span data-ttu-id="88aff-208">**Datenerfassung orchestrieren**.</span><span class="sxs-lookup"><span data-stu-id="88aff-208">**Orchestrate data ingestion**.</span></span> <span data-ttu-id="88aff-209">In einigen Fällen schreiben vorhandene Geschäftsanwendungen Datendateien für die Batchverarbeitung möglicherweise direkt in Azure Storage-Blobcontainer, wo sie von HDInsight oder Azure Data Lake Analytics genutzt werden können.</span><span class="sxs-lookup"><span data-stu-id="88aff-209">In some cases, existing business applications may write data files for batch processing directly into Azure storage blob containers, where they can be consumed by HDInsight or Azure Data Lake Analytics.</span></span> <span data-ttu-id="88aff-210">Sie werden jedoch häufig die Erfassung von Daten aus lokalen oder externen Datenquelle in den Data Lake orchestrieren müssen.</span><span class="sxs-lookup"><span data-stu-id="88aff-210">However, you will often need to orchestrate the ingestion of data from on-premises or external data sources into the data lake.</span></span> <span data-ttu-id="88aff-211">Verwenden Sie einen Orchestrierungsworkflow oder eine Orchestrierungspipeline – z.B. diejenigen, die von Azure Data Factory oder Oozie unterstützt werden –, um dieses Ziel auf vorhersehbare und kontrollierbare Weise zu erreichen.</span><span class="sxs-lookup"><span data-stu-id="88aff-211">Use an orchestration workflow or pipeline, such as those supported by Azure Data Factory or Oozie, to achieve this in a predictable and centrally manageable fashion.</span></span>

- <span data-ttu-id="88aff-212">**Vertrauliche Daten frühzeitig bereinigen**.</span><span class="sxs-lookup"><span data-stu-id="88aff-212">**Scrub sensitive data early**.</span></span> <span data-ttu-id="88aff-213">Der Workflow für die Datenerfassung sollte vertrauliche Daten frühzeitig im Prozess bereinigen, um zu verhindern, dass diese im Data Lake gespeichert werden.</span><span class="sxs-lookup"><span data-stu-id="88aff-213">The data ingestion workflow should scrub sensitive data early in the process, to avoid storing it in the data lake.</span></span>
